{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Dropout, Activation, Input, Embedding, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers, Model, Sequential, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import data_dir, models_dir\n",
    "from src.helpers import calc_metrics, plot_tfidf_classfeats_h, top_feats_by_class, init_dir, save_model, load_model, print_dict\n",
    "from src.pipeline import load_data, DATAFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "        val_targ = self.model.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(f\" — val_f1: {_val_f1:0.3f} — val_precision: {_val_precision:0.3f} — val_recall {_val_recall:0.3f}\")\n",
    "        return\n",
    " \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "X, y = data[\"text\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 202\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(\"\".join(X.values))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = X.map(lambda x: [char_indices[char] for char in x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [to_categorical(x, num_classes=len(chars)) for x in X_seq]\n",
    "X_1 = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 202)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try OHE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = X.map(lambda x: [char_indices[char] for char in x]).values\n",
    "X_seq = sequence.pad_sequences(X_seq, value=0, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(char_indices)+1, len(char_indices)))\n",
    "for word, i in char_indices.items():\n",
    "    embedding_matrix[i] = np.zeros(len(char_indices))\n",
    "    embedding_matrix[i][i-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_layer = Embedding(len(char_indices)+1,\n",
    "                                len(char_indices),\n",
    "                                weights=[embedding_matrix],\n",
    "                                #input_length=n_words,\n",
    "                                trainable=0,\n",
    "                                mask_zero=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(None,), dtype='int32')\n",
    "embedded_sequences = char_embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = Flatten()(embedded_sequences)\n",
    "x = LSTM(100)(embedded_sequences)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 202)         41006     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               121200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 162,307\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 41,006\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1, \"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, \n",
    "          batch_size=64, \n",
    "          #class_weight=weights\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len: 104\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = int(X.map(len).quantile(0.6))\n",
    "print(f\"Max len: {maxlen}\")\n",
    "print('Vectorization...')\n",
    "X_ohe = np.zeros((len(X), maxlen, len(chars)), dtype=np.bool)\n",
    "for i, text in enumerate(X.values):\n",
    "    #for t, char in enumerate(sentence):\n",
    "    idx = [(i, t, char_indices[c]) for t,c in enumerate(text) if t<maxlen]\n",
    "    #X[i, t, char_indices[char]] = 1\n",
    "    X_ohe[tuple(zip(*idx))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ohe, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(None, len(chars),))\n",
    "x = LSTM(100, input_shape=(None, len(chars)))(input_text)\n",
    "#x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, 202)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               121200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_text, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1, \"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62401402, 2.51590106])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4272 samples, validate on 1831 samples\n",
      "Epoch 1/10\n",
      "4272/4272 [==============================] - 15s 3ms/step - loss: 0.5310 - f1: 0.0072 - acc: 0.7994 - val_loss: 0.4764 - val_f1: 0.0000e+00 - val_acc: 0.8012\n",
      "Epoch 2/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.4126 - f1: 0.2804 - acc: 0.8155 - val_loss: 0.3682 - val_f1: 0.2465 - val_acc: 0.8252\n",
      "Epoch 3/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.3359 - f1: 0.5035 - acc: 0.8511 - val_loss: 0.3412 - val_f1: 0.4580 - val_acc: 0.8438\n",
      "Epoch 4/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.2981 - f1: 0.5898 - acc: 0.8720 - val_loss: 0.2978 - val_f1: 0.7304 - val_acc: 0.8880\n",
      "Epoch 5/10\n",
      "4272/4272 [==============================] - 13s 3ms/step - loss: 0.2675 - f1: 0.6588 - acc: 0.8951 - val_loss: 0.2998 - val_f1: 0.3751 - val_acc: 0.8411\n",
      "Epoch 6/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.2765 - f1: 0.4909 - acc: 0.8525 - val_loss: 0.3318 - val_f1: 0.4430 - val_acc: 0.8443\n",
      "Epoch 7/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.2659 - f1: 0.6630 - acc: 0.8841 - val_loss: 0.2566 - val_f1: 0.7607 - val_acc: 0.9039\n",
      "Epoch 8/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.1887 - f1: 0.8081 - acc: 0.9288 - val_loss: 0.2147 - val_f1: 0.7801 - val_acc: 0.9241\n",
      "Epoch 9/10\n",
      "4272/4272 [==============================] - 13s 3ms/step - loss: 0.1721 - f1: 0.8234 - acc: 0.9335 - val_loss: 0.2000 - val_f1: 0.8034 - val_acc: 0.9241\n",
      "Epoch 10/10\n",
      "4272/4272 [==============================] - 14s 3ms/step - loss: 0.1604 - f1: 0.8202 - acc: 0.9342 - val_loss: 0.2031 - val_f1: 0.7881 - val_acc: 0.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd8bc54048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, \n",
    "          batch_size=64, \n",
    "          #class_weight=weights\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
