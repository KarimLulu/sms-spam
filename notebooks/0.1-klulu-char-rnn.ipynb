{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Dropout, Activation, Input, Embedding, Flatten, concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import GlobalMaxPool1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers, Model, Sequential, callbacks, activations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from collections import Counter\n",
    "from itertools import groupby, chain\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import data_dir, models_dir\n",
    "from src.helpers import calc_metrics, plot_tfidf_classfeats_h, top_feats_by_class, init_dir, save_model, load_model, print_dict\n",
    "from src.pipeline import load_data, DATAFILE, build_transform_pipe, TF_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "X, y = data[\"text\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_embeddings(X, mask_zeros=True):\n",
    "    chars = sorted(list(set(\"\".join(X.values))))\n",
    "    char_indices = dict((c, i + mask_zeros) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i + mask_zeros, c) for i, c in enumerate(chars))\n",
    "    \n",
    "    X_seq = X.map(lambda x: [char_indices[char] for char in x]).values\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(char_indices) + mask_zeros, len(char_indices)))\n",
    "    for word, i in char_indices.items():\n",
    "        embedding_matrix[i] = np.zeros(len(char_indices))\n",
    "        embedding_matrix[i][i - mask_zeros] = 1\n",
    "\n",
    "    sequence_input = Input(shape=(200,), dtype='int32')\n",
    "    char_embedding_layer = Embedding(len(char_indices)+mask_zeros,\n",
    "                                     len(char_indices),\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    trainable=0,\n",
    "                                    mask_zero=mask_zeros\n",
    "                                   )\n",
    "    embedded_sequences = char_embedding_layer(sequence_input)\n",
    "    return sequence_input, embedded_sequences, X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X, train_features):\n",
    "    inp, x, X_seq = prepare_embeddings(X, mask_zeros=0)\n",
    "    \n",
    "    features_input = Input(shape=(train_features.shape[1],))\n",
    "    alpha = 1e-8\n",
    "    z = Dense(100, activation=activations.tanh,\n",
    "             kernel_regularizer=regularizers.l2(alpha),\n",
    "             use_bias=1\n",
    "             )(features_input)\n",
    "    z = Dropout(0.3)(z)\n",
    "    # x = Dense(50, activation=activations.tanh,\n",
    "    #          kernel_regularizer=regularizers.l2(alpha))(x)\n",
    "    # x = Dropout(0.25)(x)\n",
    "    features_output = Dense(1, activation=\"sigmoid\",\n",
    "                   use_bias=1,\n",
    "                   kernel_regularizer=regularizers.l2(alpha)\n",
    "                  )(z)\n",
    "\n",
    "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    drop1 = Dropout(0.3)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    conv2 = Conv1D(filters=32, kernel_size=5, activation='relu')(x)\n",
    "    drop2 = Dropout(0.3)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    conv3 = Conv1D(filters=32, kernel_size=7, activation='relu')(x)\n",
    "    drop3 = Dropout(0.3)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    out_conv = [flat1, flat2, flat3]\n",
    "    \n",
    "    x = concatenate(out_conv, axis = -1)    \n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    ensemble = concatenate([features_output, x])\n",
    "    ensemble_output = Dense(1, activation=\"sigmoid\", use_bias=0)(ensemble)\n",
    "    \n",
    "    model = Model(inputs=[features_input, inp], outputs=ensemble_output)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=[f1, 'accuracy'])\n",
    "    return model, X_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_seq = build_model(X, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 200, 202)     40804       input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 198, 32)      19424       embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 196, 32)      32352       embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 194, 32)      45280       embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 198, 32)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 196, 32)      0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 194, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 99, 32)       0           dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 98, 32)       0           dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 97, 32)       0           dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 3168)         0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 3136)         0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 3104)         0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 4003)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 9408)         0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 100)          400400      input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 10)           94090       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 100)          0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 10)           0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1)            101         dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 1)            11          dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 2)            0           dense_57[0][0]                   \n",
      "                                                                 dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            2           concatenate_23[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 632,464\n",
      "Trainable params: 591,660\n",
      "Non-trainable params: 40,804\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = sequence.pad_sequences(X_seq, maxlen=200, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_s, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62401402, 2.51590106])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4272 samples, validate on 1831 samples\n",
      "Epoch 1/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.4335 - f1: 0.3478 - acc: 0.8308 - val_loss: 0.3965 - val_f1: 0.6811 - val_acc: 0.9033\n",
      "Epoch 2/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.3849 - f1: 0.7309 - acc: 0.9169 - val_loss: 0.3766 - val_f1: 0.8495 - val_acc: 0.9481\n",
      "Epoch 3/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.3600 - f1: 0.9235 - acc: 0.9724 - val_loss: 0.3560 - val_f1: 0.9373 - val_acc: 0.9760\n",
      "Epoch 4/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.3411 - f1: 0.9690 - acc: 0.9876 - val_loss: 0.3470 - val_f1: 0.9429 - val_acc: 0.9782\n",
      "Epoch 5/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.3222 - f1: 0.9886 - acc: 0.9956 - val_loss: 0.3268 - val_f1: 0.9441 - val_acc: 0.9787\n",
      "Epoch 6/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.3007 - f1: 0.9916 - acc: 0.9970 - val_loss: 0.3171 - val_f1: 0.9398 - val_acc: 0.9771\n",
      "Epoch 7/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2867 - f1: 0.9963 - acc: 0.9984 - val_loss: 0.2977 - val_f1: 0.9490 - val_acc: 0.9803\n",
      "Epoch 8/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.2756 - f1: 0.9955 - acc: 0.9984 - val_loss: 0.2909 - val_f1: 0.9573 - val_acc: 0.9831\n",
      "Epoch 9/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2656 - f1: 0.9978 - acc: 0.9991 - val_loss: 0.2808 - val_f1: 0.9528 - val_acc: 0.9820\n",
      "Epoch 10/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2555 - f1: 0.9972 - acc: 0.9991 - val_loss: 0.2729 - val_f1: 0.9542 - val_acc: 0.9825\n",
      "Epoch 11/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2472 - f1: 0.9975 - acc: 0.9991 - val_loss: 0.2692 - val_f1: 0.9480 - val_acc: 0.9803\n",
      "Epoch 12/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2387 - f1: 0.9984 - acc: 0.9993 - val_loss: 0.2667 - val_f1: 0.9442 - val_acc: 0.9787\n",
      "Epoch 13/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2317 - f1: 0.9976 - acc: 0.9991 - val_loss: 0.2535 - val_f1: 0.9459 - val_acc: 0.9792\n",
      "Epoch 14/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2236 - f1: 0.9987 - acc: 0.9995 - val_loss: 0.2620 - val_f1: 0.9388 - val_acc: 0.9765\n",
      "Epoch 15/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2172 - f1: 0.9990 - acc: 0.9995 - val_loss: 0.2416 - val_f1: 0.9443 - val_acc: 0.9787\n",
      "Epoch 16/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.2107 - f1: 0.9982 - acc: 0.9993 - val_loss: 0.2370 - val_f1: 0.9442 - val_acc: 0.9787\n",
      "Epoch 17/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.2043 - f1: 0.9988 - acc: 0.9995 - val_loss: 0.2270 - val_f1: 0.9450 - val_acc: 0.9787\n",
      "Epoch 18/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1975 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.2244 - val_f1: 0.9426 - val_acc: 0.9782\n",
      "Epoch 19/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.1921 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.2208 - val_f1: 0.9446 - val_acc: 0.9787\n",
      "Epoch 20/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.1853 - f1: 0.9991 - acc: 0.9995 - val_loss: 0.2204 - val_f1: 0.9412 - val_acc: 0.9776\n",
      "Epoch 21/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1800 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.2153 - val_f1: 0.9438 - val_acc: 0.9787\n",
      "Epoch 22/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1738 - f1: 0.9990 - acc: 0.9995 - val_loss: 0.2081 - val_f1: 0.9412 - val_acc: 0.9776\n",
      "Epoch 23/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1684 - f1: 0.9985 - acc: 0.9995 - val_loss: 0.1984 - val_f1: 0.9458 - val_acc: 0.9792\n",
      "Epoch 24/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1633 - f1: 0.9985 - acc: 0.9995 - val_loss: 0.1957 - val_f1: 0.9437 - val_acc: 0.9787\n",
      "Epoch 25/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.1583 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1886 - val_f1: 0.9459 - val_acc: 0.9792\n",
      "Epoch 26/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1529 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1848 - val_f1: 0.9416 - val_acc: 0.9776\n",
      "Epoch 27/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1481 - f1: 0.9991 - acc: 0.9995 - val_loss: 0.1803 - val_f1: 0.9519 - val_acc: 0.9814\n",
      "Epoch 28/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1433 - f1: 0.9990 - acc: 0.9995 - val_loss: 0.1782 - val_f1: 0.9423 - val_acc: 0.9776\n",
      "Epoch 29/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1388 - f1: 0.9988 - acc: 0.9995 - val_loss: 0.1734 - val_f1: 0.9482 - val_acc: 0.9798\n",
      "Epoch 30/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1343 - f1: 0.9982 - acc: 0.9993 - val_loss: 0.1744 - val_f1: 0.9353 - val_acc: 0.9760\n",
      "Epoch 31/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1300 - f1: 0.9988 - acc: 0.9995 - val_loss: 0.1699 - val_f1: 0.9426 - val_acc: 0.9776\n",
      "Epoch 32/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1259 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1755 - val_f1: 0.9355 - val_acc: 0.9760\n",
      "Epoch 33/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.1218 - f1: 0.9986 - acc: 0.9995 - val_loss: 0.1624 - val_f1: 0.9436 - val_acc: 0.9782\n",
      "Epoch 34/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.1178 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1610 - val_f1: 0.9415 - val_acc: 0.9776\n",
      "Epoch 35/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1139 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1554 - val_f1: 0.9377 - val_acc: 0.9765\n",
      "Epoch 36/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1102 - f1: 0.9983 - acc: 0.9993 - val_loss: 0.1557 - val_f1: 0.9405 - val_acc: 0.9776\n",
      "Epoch 37/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1068 - f1: 0.9985 - acc: 0.9995 - val_loss: 0.1508 - val_f1: 0.9390 - val_acc: 0.9771\n",
      "Epoch 38/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.1032 - f1: 0.9988 - acc: 0.9995 - val_loss: 0.1437 - val_f1: 0.9500 - val_acc: 0.9803\n",
      "Epoch 39/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0996 - f1: 0.9988 - acc: 0.9995 - val_loss: 0.1412 - val_f1: 0.9402 - val_acc: 0.9771\n",
      "Epoch 40/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.0964 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1402 - val_f1: 0.9351 - val_acc: 0.9754\n",
      "Epoch 41/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0938 - f1: 0.9978 - acc: 0.9993 - val_loss: 0.1323 - val_f1: 0.9430 - val_acc: 0.9776\n",
      "Epoch 42/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.0902 - f1: 0.9991 - acc: 0.9995 - val_loss: 0.1425 - val_f1: 0.9366 - val_acc: 0.9760\n",
      "Epoch 43/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0871 - f1: 0.9981 - acc: 0.9993 - val_loss: 0.1289 - val_f1: 0.9406 - val_acc: 0.9776\n",
      "Epoch 44/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.0846 - f1: 0.9989 - acc: 0.9995 - val_loss: 0.1313 - val_f1: 0.9378 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0815 - f1: 0.9980 - acc: 0.9993 - val_loss: 0.1233 - val_f1: 0.9394 - val_acc: 0.9771\n",
      "Epoch 46/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.0788 - f1: 0.9984 - acc: 0.9993 - val_loss: 0.1273 - val_f1: 0.9407 - val_acc: 0.9776\n",
      "Epoch 47/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0764 - f1: 0.9984 - acc: 0.9993 - val_loss: 0.1212 - val_f1: 0.9406 - val_acc: 0.9776\n",
      "Epoch 48/50\n",
      "4272/4272 [==============================] - 20s 5ms/step - loss: 0.0738 - f1: 0.9982 - acc: 0.9993 - val_loss: 0.1201 - val_f1: 0.9393 - val_acc: 0.9771\n",
      "Epoch 49/50\n",
      "4272/4272 [==============================] - 19s 4ms/step - loss: 0.0715 - f1: 0.9981 - acc: 0.9993 - val_loss: 0.1150 - val_f1: 0.9462 - val_acc: 0.9792\n",
      "Epoch 50/50\n",
      "4272/4272 [==============================] - 19s 5ms/step - loss: 0.0687 - f1: 0.9983 - acc: 0.9993 - val_loss: 0.1193 - val_f1: 0.9348 - val_acc: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92281e7518>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit([train_features, X_train], y_train, \n",
    "          batch_size=batch_size,\n",
    "          validation_data=([test_features, X_test], y_test),\n",
    "        epochs=50,\n",
    "        shuffle=True,\n",
    "        class_weight=weights\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361004915346806"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8169014084507042"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.717032967032967"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9490909090909091"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros_like(probas)\n",
    "y_pred[probas>=0.5] = 1\n",
    "accuracy_score(y_pred, y_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)\n",
    "precision_score(y_pred, y_test)\n",
    "recall_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Char RNN (batches based on length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = X.map(lambda x: [char_indices[char] for char in x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [to_categorical(x, num_classes=len(chars)) for x in X_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(None, len(chars),))\n",
    "x = LSTM(100, input_shape=(None, len(chars)))(input_text)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, 202)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               121200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_text, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=\"rmsprop\", \n",
    "              metrics=[f1, \"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = gen_bacthes(X_train, y_train)\n",
    "gen_test = gen_bacthes(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(np.unique([len(el) for el in X_train]))\n",
    "validation_steps = len(np.unique([len(el) for el in X_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.1487 - f1: 0.6003 - acc: 0.9404 - val_loss: 0.3222 - val_f1: 0.3895 - val_acc: 0.8788\n",
      "Epoch 2/2\n",
      "309/309 [==============================] - 47s 153ms/step - loss: 0.3709 - f1: 0.5655 - acc: 0.8506 - val_loss: 0.7411 - val_f1: 0.3077 - val_acc: 0.5926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe28ca93eb8>"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen_train, validation_data=gen_test, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=2,\n",
    "                    shuffle=True\n",
    "                    #class_weight=weights\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict_generator(gen_test, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_batches = list(chain.from_iterable([next(gen_test)[-1] for _ in range(validation_steps)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36132812499999994"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.642818132168214"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5082417582417582"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.2803030303030303"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros_like(probas)\n",
    "y_pred[probas>=0.5] = 1\n",
    "f1_score(y_pred=y_pred, y_true=y_test_batches)\n",
    "accuracy_score(y_pred, y_test_batches)\n",
    "precision_score(y_pred, y_test_batches)\n",
    "recall_score(y_pred, y_test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try OHE Embeddings with zero-masking and FNN on TF-IDF + custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(build_transform_pipe(TF_PARAMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_test_text, _, _ = train_test_split(X, y, test_size=test_size, random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pipe.fit_transform(X_train_text)\n",
    "test_features = pipe.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 202\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(\"\".join(X.values))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i+1) for i, c in enumerate(chars))\n",
    "indices_char = dict((i+1, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = X.map(lambda x: [char_indices[char] for char in x]).values\n",
    "X_seq = sequence.pad_sequences(X_seq, value=0, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6103, 710)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(char_indices)+1, len(char_indices)))\n",
    "for word, i in char_indices.items():\n",
    "    embedding_matrix[i] = np.zeros(len(char_indices))\n",
    "    embedding_matrix[i][i-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding_layer = Embedding(len(char_indices)+1,\n",
    "                                len(char_indices),\n",
    "                                weights=[embedding_matrix],\n",
    "                                #input_length=n_words,\n",
    "                                trainable=0,\n",
    "                                mask_zero=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(None,), dtype='int32')\n",
    "features_input = Input(shape=(train_features.shape[1],))\n",
    "embedded_sequences = char_embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-8\n",
    "z = Dense(100, activation=activations.tanh,\n",
    "         kernel_regularizer=regularizers.l2(alpha),\n",
    "         use_bias=1\n",
    "         )(features_input)\n",
    "z = Dropout(0.3)(z)\n",
    "# x = Dense(50, activation=activations.tanh,\n",
    "#          kernel_regularizer=regularizers.l2(alpha))(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "features_output = Dense(1, activation=\"sigmoid\",\n",
    "               use_bias=1,\n",
    "               kernel_regularizer=regularizers.l2(alpha)\n",
    "              )(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = Flatten()(embedded_sequences)\n",
    "x = LSTM(100, kernel_regularizer=regularizers.l2(1e-8))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "rnn_output = Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = concatenate([features_output, rnn_output])\n",
    "ensemble_output = Dense(1, activation=\"sigmoid\", use_bias=0)(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 4003)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 202)    41006       input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 100)          400400      input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 100)          121200      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 100)          0           dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 100)          0           lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1)            101         dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1)            101         dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2)            0           dense_62[0][0]                   \n",
      "                                                                 dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            2           concatenate_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 562,810\n",
      "Trainable params: 521,804\n",
      "Non-trainable params: 41,006\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[sequence_input, features_input], outputs=ensemble_output)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=[f1, \"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4272 samples, validate on 1831 samples\n",
      "Epoch 1/1\n",
      "4272/4272 [==============================] - 114s 27ms/step - loss: 0.3389 - f1: 0.9967 - acc: 0.9986 - val_loss: 0.3465 - val_f1: 0.9465 - val_acc: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2461836a0>"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, train_features], y_train, \n",
    "          validation_data=([X_test, test_features], y_test), \n",
    "          epochs=1, \n",
    "          batch_size=64, \n",
    "          class_weight=weights,\n",
    "          shuffle=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict([X_test, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814309120699072"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9530386740331492"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9478021978021978"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros_like(probas)\n",
    "y_pred[probas>=0.5] = 1\n",
    "accuracy_score(y_pred, y_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)\n",
    "precision_score(y_pred, y_test)\n",
    "recall_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 202\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(\"\".join(X.values))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max len: 80\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 80\n",
    "print(f\"Max len: {maxlen}\")\n",
    "print('Vectorization...')\n",
    "X_ohe = np.zeros((len(X), maxlen, len(chars)), dtype=np.bool)\n",
    "for i, text in enumerate(X.values):\n",
    "    #for t, char in enumerate(sentence):\n",
    "    idx = [(i, t, char_indices[c]) for t,c in enumerate(text) if t < maxlen]\n",
    "    #X[i, t, char_indices[char]] = 1\n",
    "    X_ohe[tuple(zip(*idx))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6103, 80, 202)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ohe, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input = Input(shape=(train_features.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-8\n",
    "z = Dense(100, activation=activations.tanh,\n",
    "         kernel_regularizer=regularizers.l2(alpha),\n",
    "         use_bias=1\n",
    "         )(features_input)\n",
    "z = Dropout(0.3)(z)\n",
    "# x = Dense(50, activation=activations.tanh,\n",
    "#          kernel_regularizer=regularizers.l2(alpha))(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "features_output = Dense(1, activation=\"sigmoid\",\n",
    "               use_bias=1,\n",
    "               kernel_regularizer=regularizers.l2(alpha)\n",
    "              )(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(maxlen, len(chars),))\n",
    "x = LSTM(100, kernel_regularizer=regularizers.l2(1e-8))(input_text)\n",
    "x = Dropout(0.3)(x)\n",
    "rnn_output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = concatenate([features_output, rnn_output])\n",
    "ensemble_output = Dense(1, activation=\"sigmoid\")(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           (None, 4003)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 80, 202)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 100)          400400      input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 100)          121200      input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 100)          0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 100)          0           lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 1)            101         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1)            101         dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2)            0           dense_49[0][0]                   \n",
      "                                                                 dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            3           concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 521,805\n",
      "Trainable params: 521,805\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_text, features_input], outputs=ensemble_output)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1, \"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4272 samples, validate on 1831 samples\n",
      "Epoch 1/20\n",
      "4272/4272 [==============================] - 15s 4ms/step - loss: 0.4380 - f1: 0.0000e+00 - acc: 0.8013 - val_loss: 0.3953 - val_f1: 0.0000e+00 - val_acc: 0.8012\n",
      "Epoch 2/20\n",
      "4272/4272 [==============================] - 12s 3ms/step - loss: 0.3775 - f1: 0.0000e+00 - acc: 0.8013 - val_loss: 0.3714 - val_f1: 0.0000e+00 - val_acc: 0.8012\n",
      "Epoch 3/20\n",
      "4272/4272 [==============================] - 12s 3ms/step - loss: 0.3552 - f1: 0.0000e+00 - acc: 0.8013 - val_loss: 0.3579 - val_f1: 0.0000e+00 - val_acc: 0.8012\n",
      "Epoch 4/20\n",
      "3200/4272 [=====================>........] - ETA: 2s - loss: 0.3418 - f1: 0.0000e+00 - acc: 0.8031"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-680-223a0be89878>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m          )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X_train, train_features], \n",
    "          y_train, \n",
    "          validation_data=([X_test, test_features], y_test), \n",
    "          epochs=20, \n",
    "          batch_size=64, \n",
    "          class_weight=weights\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict([X_test, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770617149098854"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.zeros_like(probas)\n",
    "y_pred[probas>=0.5] = 1\n",
    "accuracy_score(y_pred, y_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)\n",
    "precision_score(y_pred, y_test)\n",
    "recall_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
