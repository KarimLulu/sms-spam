{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.transformers\n",
    "%aimport src.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from xml.etree.ElementTree import iterparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import regex\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer, word_tokenize\n",
    "import dill\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from functools import partial\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import data_dir, models_dir\n",
    "from src.helpers import (calc_metrics, plot_tfidf_classfeats_h, top_feats_by_class, \n",
    "                         init_dir, save_model, load_model, print_dict)\n",
    "from src.transformers import (TfIdfLen, ModelTransformer, MatchPattern, Length, \n",
    "                              Converter, Transformer, unsquash, Select)\n",
    "from src.pipeline import (grid_search, analyze_model, load_data, build_transform_pipe, TF_PARAMS, PATTERNS,\n",
    "                          get_vec_pipe, get_pattern_pipe, TOKEN_FEATURES, build_all_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokens\"] = data[\"text\"].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4272, Num. of test: 1831\n"
     ]
    }
   ],
   "source": [
    "X = data[[\"text\", \"tokens\"]]\n",
    "y = data[\"label\"]\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUBER_URLINTEXT_PAT = re.compile(r\"\"\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)\n",
    "                                  (?:[^\\s()<>]|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+\n",
    "                                  (?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>\n",
    "                                  ?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019]))\"\"\", re.X)\n",
    "WEB_URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.]\n",
    "                (?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro\n",
    "                |tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh\n",
    "                |bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy\n",
    "                |cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi\n",
    "                |gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo\n",
    "                |jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk\n",
    "                |ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe\n",
    "                |pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl\n",
    "                |sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug\n",
    "                |uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\n",
    "                \\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|\n",
    "                [^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.]\n",
    "                (?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post\n",
    "                |pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|\n",
    "                bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co\n",
    "                |cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga\n",
    "                |gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in\n",
    "                |io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu\n",
    "                |lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng\n",
    "                |ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa\n",
    "                |sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk\n",
    "                |tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za\n",
    "                |zm|zw)\\b/?(?!@)))\"\"\"\n",
    "CURRENCY_PATT = u\"[$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_params = {'lowercase': True,\n",
    " 'analyzer': 'char_wb',\n",
    " 'stop_words': None,\n",
    " 'ngram_range': (4, 4),\n",
    " 'min_df': 0.0,\n",
    " 'max_df': 1.0,\n",
    " 'preprocessor': None,\n",
    " 'max_features': 4000,\n",
    " 'norm': '',\n",
    " 'use_idf': 1}\n",
    "patterns = [(r\"[\\(\\d][\\d\\s\\(\\)-]{8,15}\\d\", {\"name\": \"phone\",\n",
    "                                            \"is_len\": 0}),\n",
    "           (r\"%|taxi|скид(?:к|очн)|ц[іе]н|знижк|такс[иі]|промо|акц[іи]|bonus|бонус\", {\"name\": \"custom\",\n",
    "                                  \"is_len\": 0,\n",
    "                                  \"flags\": re.I | re.U}),\n",
    "#            (r\"[+-<>/^]\", {\"name\": \"math_ops\", \"is_len\": 0}),\n",
    "            (r\"[.]\", {\"name\": \"dot\", \"is_len\": 0}),\n",
    "#            (WEB_URL_REGEX, {\"name\": \"url\", \"is_len\": 0, \"flags\": re.X}),\n",
    "            (CURRENCY_PATT, {\"name\": \"currency\", \"is_len\": 0, \"flags\": re.U}),\n",
    "#            (r\"[*]\", {\"name\": \"special_symbols\", \"is_len\": 0})\n",
    "            (r\":\\)|:\\(|-_-|:p|:v|:\\*|:o|B-\\)|:’\\(\", {\"name\": \"emoji\", \"is_len\": 0, \"flags\": re.U}),\n",
    "            (r\"[0-9]{2,4}[.-/][0-9]{2,4}[.-/][0-9]{2,4}\", {\"name\": \"date\", \"is_len\": 0})\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_pipe(tokenizer=word_tokenize, features=TOKEN_FEATURES):\n",
    "    token_features = TokenFeatures(tokenizer, features=features)\n",
    "    tok_pipe = [\n",
    "        (\"selector\", Select([\"tokens\"], to_np=0)),\n",
    "        ('tok', token_features)]\n",
    "    return Pipeline(tok_pipe)\n",
    "\n",
    "def get_vec_pipe(add_len=True, tfidf_params={}):\n",
    "    vectorizer = TfIdfLen(add_len, **tfidf_params)\n",
    "    vec_pipe = [\n",
    "        ('vec', vectorizer)]\n",
    "    return Pipeline(vec_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_pipe(patterns):\n",
    "    pipes = []\n",
    "    for i, (patt, params) in enumerate(patterns):\n",
    "        kwargs = params.copy()\n",
    "        name = kwargs.pop(\"name\") + \"_\" + str(i)\n",
    "        transformer = MatchPattern(pattern=patt, **kwargs)\n",
    "        pipes.append((name, transformer))\n",
    "    return pipes\n",
    "\n",
    "def get_len_pipe(use_tfidf=True, vec_pipe=None):\n",
    "    len_pipe = [(\"length\", Length(use_tfidf))]\n",
    "    if use_tfidf:\n",
    "        len_pipe.insert(0, (\"vec\", vec_pipe))\n",
    "    return Pipeline(len_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform_pipe(tf_params=tf_params, add_len=True, vec_mode=\"add\", patterns=patterns,\n",
    "                         tokenizer=word_tokenize, features=TOKEN_FEATURES):\n",
    "    vec_pipe = get_vec_pipe(add_len, tf_params)\n",
    "    if vec_mode == \"only\":\n",
    "        return vec_pipe\n",
    "    patt_pipe = get_pattern_pipe(patterns)\n",
    "    chain = [\n",
    "        ('selector', Select([\"text\"], to_np=0)),\n",
    "        ('converter', Converter()),\n",
    "        ('union', FeatureUnion([\n",
    "            ('vec', vec_pipe),\n",
    "            *patt_pipe\n",
    "        ]))\n",
    "    ]\n",
    "    tok_pipe = get_tokens_pipe(tokenizer, features)\n",
    "    final_chain = FeatureUnion([(\"chain\", Pipeline(chain)),\n",
    "                                (\"tok\", tok_pipe)])\n",
    "    return [(\"final_chain\", final_chain)]\n",
    "\n",
    "def build_classifier(name, seed=25):\n",
    "    if name == \"logit\":\n",
    "        model = LogisticRegression(C=1, class_weight=\"balanced\", random_state=seed, penalty=\"l2\")\n",
    "        model.grid_s = {f'{name}__C' : (0.1, 0.2, 0.3, 0.4, 0.5, 1, 5, 10)}\n",
    "        model.grid_b = {f'{name}__C' : [(1)]}\n",
    "    elif name == \"nb\":\n",
    "        model = MultinomialNB(alpha=0.1) #class_prior=[0.5, 0.5])\n",
    "        model.grid_s = {f'{name}__alpha' : (0.1, 0.5, 1, 5, 10)}\n",
    "        model.grid_b = {f'{name}__alpha' : [(1)]}\n",
    "    model.name = name\n",
    "    return model\n",
    "\n",
    "def get_estimator_pipe(name, model, tf_params, vec_mode=\"add\", patterns=patterns, features=TOKEN_FEATURES):\n",
    "    chain = build_transform_pipe(tf_params, vec_mode=vec_mode, patterns=patterns, features=features)\n",
    "    chain.append((name, model))\n",
    "    pipe = Pipeline(chain)\n",
    "    pipe.name = name\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1831x4007 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 89252 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_pipe = get_vec_pipe(True, tf_params)\n",
    "patt_pipe = get_pattern_pipe(patterns)\n",
    "chain = [\n",
    "    ('selector', Select([\"text\"], to_np=0)),\n",
    "      ('converter', Converter()),\n",
    "    ('union', FeatureUnion([\n",
    "        ('vec', vec_pipe),\n",
    "        *patt_pipe\n",
    "   ]))\n",
    "]\n",
    "pipe = Pipeline(chain)\n",
    "pipe.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lower(tokens):\n",
    "    return any(token.islower() for token in tokens)\n",
    "\n",
    "def is_upper(tokens):\n",
    "    return any(token.isupper() for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenFeatures(Transformer):\n",
    "\n",
    "    def __init__(self, tokenizer=word_tokenize, features=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.features = features\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return dict()\n",
    "\n",
    "    def _get_features(self, tokens):\n",
    "        output = []\n",
    "        for f in self.features:\n",
    "            output.append(eval(f)(tokens))\n",
    "        return np.array(output)\n",
    "    \n",
    "    def _job(self, text):\n",
    "        tokens = self.tokenizer(text)\n",
    "        return self._get_features(tokens)\n",
    "        \n",
    "    def transform(self, X, **kwargs):  \n",
    "        rez = []\n",
    "        for record in X:\n",
    "            temp = self._get_features(record)\n",
    "            rez.append(temp)\n",
    "        return np.array(rez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = build_transform_pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('final_chain', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('chain', Pipeline(memory=None,\n",
       "     steps=[('selector', <src.transformers.Select object at 0x7f7c265a4278>), ('converter', <src.transformers.Converter object at 0x7f7c266157b8>), ('union', FeatureUnion(n_jobs=1,\n",
       "       transform...alty='l2', random_state=25,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = build_classifier(\"logit\")\n",
    "pipe = get_estimator_pipe(clf.name, clf, tf_params)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability ham: 41.728%\n",
      "Probability spam: 58.272%\n"
     ]
    }
   ],
   "source": [
    "sms = \"поїдем до них на таксі?\"\n",
    "sms_df = pd.DataFrame({\"text\": sms, \"tokens\": word_tokenize(sms)})\n",
    "ham, spam = pipe.predict_proba(sms_df)[0]\n",
    "print(f\"Probability ham: {ham*100:0.3f}%\\nProbability spam: {spam*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'[0-9]{2,4}[.-/\\\\\\\\][0-9]{2,4}[.-/\\\\\\\\][0-9]{2,4}'\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['21.04.2016']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = r\"[0-9]{2,4}[.-/][0-9]{2,4}[.-/][0-9]{2,4}\"\n",
    "repr(p)\n",
    "re.findall(p, \"21.04.2016\", re.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypertuning model 1 out of 1: logit\n",
      "================================================================================\n",
      "Best score on training set (CV): 0.960\n",
      "Best parameters set:\n",
      "0.9587 (+/-0.0029) for {'logit__C': 0.1}: [0.9694501  0.95652174 0.95218295 0.95867769 0.95687885]\n",
      "0.9599 (+/-0.0041) for {'logit__C': 0.2}: [0.97352342 0.95652174 0.95       0.96465696 0.95473251]\n",
      "0.9590 (+/-0.0041) for {'logit__C': 0.3}: [0.97142857 0.95652174 0.94780793 0.96465696 0.95473251]\n",
      "0.9573 (+/-0.0037) for {'logit__C': 0.4}: [0.96734694 0.95652174 0.94560669 0.9625     0.95473251]\n",
      "0.9569 (+/-0.0034) for {'logit__C': 0.5}: [0.96523517 0.95652174 0.94560669 0.9625     0.95473251]\n",
      "0.9556 (+/-0.0035) for {'logit__C': 1}: [0.96523517 0.95652174 0.94560669 0.96033403 0.95041322]\n",
      "0.9548 (+/-0.0037) for {'logit__C': 5}: [0.96326531 0.95850622 0.94560669 0.96049896 0.94605809]\n",
      "0.9527 (+/-0.0032) for {'logit__C': 10}: [0.95705521 0.95850622 0.94560669 0.95833333 0.94409938]\n"
     ]
    }
   ],
   "source": [
    "best_estimators, best_scores = grid_search(patterns=patterns, estimator_names=[\"logit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'logit__C': 0.2},\n",
       "  'mean': 0.9598908445178538,\n",
       "  'scores': array([0.97352342, 0.95652174, 0.95      , 0.96465696, 0.95473251]),\n",
       "  'std': 0.008298807992172147}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'logit__C': 0.2},\n",
       "  'mean': 0.9599238561276642,\n",
       "  'scores': array([0.97154472, 0.95867769, 0.95      , 0.9625    , 0.95687885]),\n",
       "  'std': 0.007085036990868852}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall results\n",
      "AUC: 1.00 +/- 0.0011\n",
      "Accuracy: 0.98 +/- 0.0036\n",
      "F1: 0.96 +/- 0.0093\n",
      "Precision: 0.96 +/- 0.0074\n",
      "Recall: 0.96 +/- 0.0150\n",
      "\n",
      "Averaged confusion matrix\n",
      "      pred_ham  pred_spam\n",
      "ham      968.8        8.6\n",
      "spam      10.8      232.4\n",
      "\n",
      "Mean metrics\n",
      "accuracy: 0.984\n",
      "specificity: 0.964\n",
      "recall: 0.989\n",
      "precision: 0.991\n",
      "f1: 0.990\n"
     ]
    }
   ],
   "source": [
    "scores, results, conf_matrix, fnp = analyze_model(model=best_estimators[0], log_fold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tviy kod 90F7C416K. Obminyay yogo na Pepsi-Bonus v KFC Vokzal Pivdenniy z 16.04.2015 do 16.05.2015\n",
      "\n",
      "Z 04/07 centr VOLIA po vul.Kikvidze 1/2 bude zachineno na remont. Najblizhchi adresy dlya zvernen: vul.Vasylkivska 4, vul.Knazhyi Zaton 2/30\n",
      "\n",
      "Women's Day When: 7 March 22:00 Where: TAO Restaurant & Dance Bar 06735\n",
      "\n",
      "Lyubyi druzhe! Cherez nadzvychaino velyku kilkist otrymanyh lystiv - rozigrash pryziv vidbudetsya 27.05. Dyakuemo za uchast! Bazhaemo peremohy! hwclub.com.ua\n",
      "\n",
      "Магазин \"Карфур\" стал больше, новый товар. Открытие 22.10 в 11:00\n",
      "\n",
      "Время подарков пришло! Цитрус продлил работу на час! time.citrus.ua\n",
      "\n",
      "Київ, ми знизили ціни на uberX! Відтепер поїздки по місту - від 25 грн\n",
      "\n",
      "Використай нагоду! На вашому рахунку 31 бонусів. Витрачай до 05.03!\n",
      "\n",
      "Заказ№4999 ожидает Вас по адресу пр.ЛесяКурбаса,16-а до 19.03\n",
      "\n",
      "Tomorrow's forecast in SOMA South Park, San Francisco is Clear. https://m.twil.io/kYotCFy\n",
      "\n",
      "Новые график в КАРФУР!Пт-80%Чт-70%Ср-60%Вт-50%Пн-30%Вс-10%,Сб-ЗАВОЗ!\n",
      "\n",
      "Москитные сетки Регулировка окон Ремонт,чистка кондиционера 0675136192\n",
      "\n",
      "Привіт! Нагадуємо, що вже сьогодні відбудеться перше заняття на курсі Data Science. Natural Language Processing у Projector (вул. Воздвиженська, 34А). Початок о 19:30. Гарного дня!\n",
      "\n",
      "Karim Maksimovich! Priobretaite bilety na poezd po cenam kassy vokzala kruglosutochno v Privat24 ili na bilet.pb.ua! pb.ua/1551\n",
      "\n",
      "Послугу Інтернет Тиждень підключено!Ви користуєтесь Інтернетом за тарифами 15грн за кожні 500МБ. Термін дії МБ 7днів. Для перевірки залишку Інтернет-пакету наберіть *121#.\n",
      "\n",
      "З 19.04.17 змінюється тариф на роумінг в Білорусі: дзвінки 10хв - 45грн, 100МБ- 55грн, 15 вихідних SMS- 20грн. Пакет до кінця доби (за Київським часом), не залежить від оператора в країні. Кількість пакетів необмежена. Деталі: s.lifecell.ua/74 \n",
      "\n",
      "Шановний абоненте, вітаємо Вас з травневими вихідними! Бажаємо сонячного тепла і приємного спілкування з рідними та друзями щодня! Дякуємо за довіру, Ваш lifecell\n",
      "\n",
      "Привіт! UNFPA, Фонд народонаселення ООН, хоче почути Вашу думку. Чому дівчата менше орієнтовані на кар’єру в науково-технічній сфері? 1.Невпевнені у своїх силах і талантах 2.У школі погано вчили відповідні предмети 3.Вважають, що робота у цій сфері може негативно вплинути на особисте життя 4.Не цікаво 5.Це чоловіча сфера 6.Недостатньо обізнані про цю сферу 7.Ризик високої конкуренції 8.Інше(вкажіть)\n",
      "\n",
      "І останнє запитання: Яка ймовірність, що Ви будете  рекомендувати U-Report вашим друзям? Використовуйте шкалу від 0 до 10, де 0-точно не буду рекомендувати, а 10 – точно буду рекомендувати.\n",
      "\n",
      "Удача! День Белья в Milavitsa 20-21.08! Ты успеешь! Инфо:0504470777\n",
      "\n",
      "Letnie skidki v TAC!- 50% na postelnoe belie Satin!Tolko 19-25 iyunia. ul.Baseynaya 5A tel.0668475131 DiscontInfo\n",
      "\n",
      "Чекаємо вас сьогодні на MustHave fashion-лекції в Mozart Hotel за адресою Ланжеронівська 13. О 15:00. До зустрічі!\n",
      "\n",
      "Вона зачекалася:) Твоя перша ЕКО-картка вже у відділенні УКРГАЗБАНКУ у м. Київ 0800309000\n",
      "\n",
      "Останні 3 дні! 2 пари літа за 1399 грн до 17.09.17\n",
      "\n",
      "Kontrol kachestva Lamoda: esli u vas byla problema s zakazom, otpravte 1 v otvet, i my perezvonim vam, ili napishite nam na problema@lamoda.ua. Spasibo:-)\n",
      "\n",
      "Фестиваль ягнятины в Кувшине! Семь вкуснейших блюд из премиального и деликатесного мяса! Ждем вас в гости!(067)4687258\n",
      "\n",
      "Приглашаем на Фестиваль ягнятины в Кувшине! Семь вкуснейших блюд из премиального и деликатесного мяса! Ждем вас в гости!(067)4687258\n",
      "\n",
      "Фестиваль хинкали в Кувшине!С индейкой,форелью,грибами,мясом дикого кабана,шпинатом!Ждем в гости!(067)4687258\n",
      "\n",
      "Приглашаем на выходные в \"Кувшин\"! Новое меню легендарных кавказских блюд, живая музыка, специальная  детская анимация! Фёдорова 10,0674687258\n",
      "\n",
      "Новая традиция выходных-уникальный гиссарский баран в \"Кувшине\"! Особо нежная и вкусная баранина!  Шурпа, кебаб, шашлык, стейк!Спешите попробовать! ул.Федорова, 10.Тел. 0674687258.\n",
      "\n",
      "Приглашаем на выходные в \"Кувшин\"!Блюда из особого Гиссарского барана, фирменный плов от Шефа, а в воскресенье-7 видов хинкали!Атмосфера праздника и грузинского застолья! Ждем в гости! 380674687258\n",
      "\n",
      "Z DNEM NARODZHENNYA! Budte z tymy, kogo liubyte! Robit te, u scho viryte! Zdorovia ta nathnennya! Robert Kossmann, zast. Golovy Pravlinnya Raiffeisen Bank Aval\n",
      "\n",
      "Shanovnyi Kliente, Vam dostupno 24750 UAH kredytnyh koshtiv vid Raiffeisen Banku Aval! Zavitayte do viddilennia! Info 0800500500\n",
      "\n",
      "Тепер так легко і вигідно надіслати гроші своїм рідним! Заходьте https://paycell.lifecell.ua/transfer та переводьте кошти з мобільного на будь-яку банківську карту!\n",
      "\n",
      "Akcija v oktjabre! Francuzskoe narashhivanie nogtejj - 199 griven! Vash master Oksana zhdet Vas) 063 516 80 90. Лютеранская,3\n",
      "\n",
      "Cлухайте пісні улюблених виконавців без перешкод та в цифровій якості у музичному додатку fizy! Завантажуйте http://fizy.com.ua/ob\n",
      "\n",
      "1-11 марта 1+1=3 на белье и дом.одежду  0674338487 hunkemoller.com.ua\n",
      "\n",
      "MGI запрошує Вас на концерт хору із Арканзасу сьогодні 26.04 о 19:00\n",
      "\n",
      "Встречаемся уже завтра в новом клубе! L sektor сменил прописку - ул. Ямская 35/34 Новых побед в 2018! Твой Lsektor.com\n",
      "\n",
      "Ваш борг перед ТОВ Воля Кабель передано до CreditExpress.У Вас 4 години для сплати боргу!№ квитанції повідомте за тел 0444920550\n",
      "\n",
      "Якість за суперціною! Оправи BEST-150 грн, EXO-200 грн. luxoptica.ua\n",
      "\n",
      "6 лінз PureVision2+розчин Biotrue 60 ml = 654 грн. Деталі luxoptica.ua\n",
      "\n",
      "Обідній сет за ціною піци: 79 грн. В усіх ресторанах з 12:00 до 15:00\n",
      "\n",
      "Чтобы обнять близкого человека, для начала лучше освободить руки:) Ваша персональная скидка -14% до 14-го февраля на bagman.ua\n",
      "\n",
      "Безмежне спілкування! 4 ГБ Інтернету та 60 хв. на інші номери по Україні за поповнення на 70 грн, 3 ГБ та 40 хв. за поповнення на 50 грн, 2 ГБ та 20 хв. за поповнення на 30 грн. Поповнення одним платежем до 02.06.2018 (включно). Умови за номером 2153 (безкоштовно)\n",
      "\n",
      "ФИНАЛЬНАЯ РАСПРОДАЖА ⚠️   ⚠️   ⚠️ До - 70% на более 1000 ароматов популярной парфюмерии.🌺 *** Спешите. До конца акции осталось 3 дня ***✈️    \n",
      "\n",
      "Priglashaem v novij salon DOM OPTIKI na ul.Saksaganskogo,70/16! V chest' otkritija - PODARKI pokupateljam! (073)118-45-59, dom-optiki.ua\n",
      "\n",
      " \"OSCHADBANK\"  VASHU KARTKU ZABLOKOVANO.  Dlya razblokyvanya zvernicya do kontakt-centru za nom. 0919535656 goryacay liniya OSCHADBANK   \n",
      "\n",
      "The Prodigy, Kasabian, Royksopp, Onuka з 28.06 по 02.07 на фестивалі Atlas Weekend. 8 сцен і 200 виконавців! Зустрічаємося у Києві на ВНДГ. Інфо та квитки: atlasweekend.com\n",
      "\n",
      "\"Oschadbank\" Shanovnyy kliente vashu kartku  zablokovano na 92 na vashomu rahunku -0.00 UAN .Detali za nomerom: +38091-922-47-01;    \n",
      "\n",
      "Заберіть 370000 грн готівкою. Дзвоніть: 0 800 30 10 40 (безкоштовно)\n",
      "\n",
      "Спеши до 20.04.18 всего 330гр абонемент Пасхальный месяц тел0672400404\n",
      "\n",
      "Darina, скачайте наше приложение и получите подтверждение бронирования на телефон! booking.com/App-9nhcP09D (ссылка скоро перестанет действовать)\n",
      "\n",
      "Заказывайте Вкусных Раков  XS-250 S - 400.     M- 600.  Грн  L - 790 XL-980 Тел:0960708999 Rachevnya.com.ua.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn, fp = fnp[\"fn\"], fnp[\"fp\"]\n",
    "for el in X.iloc[fn][\"text\"]:\n",
    "    print(el+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109932</td>\n",
       "      <td>5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636704</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean  count\n",
       "l                 \n",
       "0  0.109932   5276\n",
       "1  0.636704    534\n",
       "2  1.000000    220\n",
       "3  1.000000     63\n",
       "4  1.000000      7\n",
       "5  1.000000      1\n",
       "6  1.000000      1\n",
       "7  1.000000      1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data\n",
    " .assign(l=lambda x: x[\"text\"].str.findall(r\"%|taxi|скид(?:к|очн)|ц[іе]н|знижк|такс[иі]|промо|акц[іи]|bonus|бонус\", flags=re.I|re.U).map(len))\n",
    ").groupby(\"l\")[\"label\"].agg([\"mean\", \"count\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
