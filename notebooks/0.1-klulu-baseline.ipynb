{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import string\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import (roc_auc_score, precision_score, recall_score, \n",
    "                             confusion_matrix, accuracy_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.config\n",
    "from src.config import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "stop = set(stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_test, pred, proba=None, labels=[\"ham\", \"spam\"], print_=True):\n",
    "    output = {}\n",
    "    if proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, proba)\n",
    "        output[\"AUC\"] = roc_auc\n",
    "    output[\"Recall\"] = recall_score(y_test, pred)\n",
    "    output[\"Precision\"] = precision_score(y_test, pred)\n",
    "    output[\"F1\"] = f1_score(y_test, pred)\n",
    "    output[\"accuracy\"] = accuracy_score(y_test, pred)\n",
    "    if labels is not None:\n",
    "        index = labels\n",
    "        columns = [\"pred_\" + el for el in index]\n",
    "    else:\n",
    "        columns = None\n",
    "        index = None\n",
    "    output[\"conf_matrix\"] = pd.DataFrame(confusion_matrix(y_test, pred), \n",
    "                                         columns=columns, index=index)\n",
    "    if print_:\n",
    "        for key, value in output.items():\n",
    "            if \"matrix\" in key:\n",
    "                print(value)\n",
    "            else:\n",
    "                print(f\"{key}: {value:0.3f}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    \"\"\"\n",
    "    Preprocess input document\n",
    "    \"\"\"\n",
    "    def __init__(self, stopwords=stop, remove_stop=True, min_length=0):\n",
    "        self.stopwords = stopwords\n",
    "        self.remove_stop = remove_stop\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        if not isinstance(doc, (str, bytes)):\n",
    "            doc = str(doc)\n",
    "        if self.remove_stop:\n",
    "            tokens = [el.strip(' \\n\\t\\r').lower() for el in doc.split() if el.strip().lower() not in self.stopwords]\n",
    "        else:\n",
    "            tokens = [el.strip(' \\n\\t\\r').lower() for el in doc.split()]\n",
    "        return ' '.join(filter(lambda x: len(x)>=self.min_length, tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"ham\": 0,\n",
    "           \"spam\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMS Collection\n",
    "filename = \"SMSSpamCollection.txt\"\n",
    "df_coll = pd.read_csv(data_dir / filename, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "df_coll[\"label\"] = df_coll[\"label\"].map(mapping)\n",
    "df_coll[\"source\"] = \"coll\"\n",
    "df_coll[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1353\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMS from DIT - only spam\n",
    "tree = ET.parse(data_dir / 'spam.xml')\n",
    "root = tree.getroot()\n",
    "data = []\n",
    "for sms in root.iterfind(\"sms\"):\n",
    "    record = {child.tag:child.text for child in sms.getchildren()}\n",
    "    data.append(record)\n",
    "df_dit = pd.DataFrame(data).rename(columns={\"class\": \"label\"})\n",
    "df_dit[\"label\"] = df_dit[\"label\"].map(lambda x: mapping.get(x, x))\n",
    "df_dit[\"label\"].value_counts()\n",
    "# only spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_coll, df_dit], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>almeida</td>\n",
       "      <td>1</td>\n",
       "      <td>(Bank of Granite issues Strong-Buy) EXPLOSIVE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>(Bank of Granite issues Strong-Buy) EXPLOSIVE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>almeida</td>\n",
       "      <td>1</td>\n",
       "      <td>* FREE* POLYPHONIC RINGTONE Text SUPER to 8713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>* FREE* POLYPHONIC RINGTONE Text SUPER to 8713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>almeida</td>\n",
       "      <td>1</td>\n",
       "      <td>**FREE MESSAGE**Thanks for using the Auction S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>**FREE MESSAGE**Thanks for using the Auction S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>almeida</td>\n",
       "      <td>1</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>almeida</td>\n",
       "      <td>1</td>\n",
       "      <td>+449071512431 URGENT! This is the 2nd attempt ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  label                                               text\n",
       "476   almeida      1  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n",
       "3991     coll      1  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n",
       "572   almeida      1  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
       "4903     coll      1  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
       "568   almeida      1  **FREE MESSAGE**Thanks for using the Auction S...\n",
       "4863     coll      1  **FREE MESSAGE**Thanks for using the Auction S...\n",
       "2124     coll      1  +123 Congratulations - in this week's competit...\n",
       "69    almeida      1  +123 Congratulations - in this week's competit...\n",
       "505      coll      1  +123 Congratulations - in this week's competit...\n",
       "100   almeida      1  +449071512431 URGENT! This is the 2nd attempt ..."
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up duplicates\n",
    "s = df.text.map(lambda x: x.strip(\" \\t\\n\\r\").lower())\n",
    "duplicates = df.loc[s.duplicated(), \"text\"]\n",
    "df.loc[df.text.isin(duplicates), [\"source\", \"label\", \"text\"]].sort_values(by=\"text\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.768903\n",
       "1    0.231097\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.loc[~s.duplicated()]\n",
    "df_clean.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of train: 4697, Num. of test: 1175\n"
     ]
    }
   ],
   "source": [
    "X = df_clean[\"text\"]\n",
    "y = df_clean[\"label\"]\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42,\n",
    "                                                    stratify=y)\n",
    "print(f\"Num. of train: {len(X_train)}, Num. of test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's implement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_likelihood(data, vectorizer, y):\n",
    "    tfidf =  vectorizer.fit_transform(data).toarray()\n",
    "    prob_spam = tfidf[y > 0].sum(axis=0)\n",
    "    prob_ham = tfidf[y < 1].sum(axis=0)\n",
    "    prob_spam /= np.sum(prob_spam)\n",
    "    prob_ham /= np.sum(prob_ham)\n",
    "    return np.vstack((prob_ham, prob_spam)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, vectorizer, priors, likelihood):\n",
    "    tf = vectorizer.transform(X_test).toarray() \n",
    "    prob = tf[:, :, np.newaxis] * likelihood[np.newaxis, :, :]\n",
    "    prob[prob==0] = 1\n",
    "    score = np.exp(np.log(prob).sum(axis=1)) * priors\n",
    "    score[score.max(axis=1)==0] = eps\n",
    "    return score / score.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_params = {\"lowercase\": True,\n",
    "             \"analyzer\": \"char_wb\",\n",
    "             \"stop_words\": stop,\n",
    "             \"ngram_range\": (3, 3),\n",
    "             \"min_df\": 1,\n",
    "             \"max_df\": 1.0,\n",
    "             \"preprocessor\": None,#Preprocessor(),\n",
    "             \"max_features\": 3500,\n",
    "             \"norm\": \"l2\"*0,\n",
    "             \"use_idf\": 1\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "priors = y_train.value_counts(normalize=True).values\n",
    "vectorizer = TfidfVectorizer(**tf_params)\n",
    "train = vectorizer.fit_transform(X_train)\n",
    "test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.960\n",
      "Recall: 0.890\n",
      "Precision: 0.906\n",
      "F1: 0.898\n",
      "accuracy: 0.953\n",
      "      pred_ham  pred_spam\n",
      "ham        878         25\n",
      "spam        30        242\n"
     ]
    }
   ],
   "source": [
    "likelihood = calc_likelihood(X_train, vectorizer, y_train)\n",
    "likelihood[likelihood==0] = eps\n",
    "likelihood[likelihood==1] = 1 - eps\n",
    "#assert np.amax(np.fabs(np.sum(likelihood, axis=1) - train.toarray().sum(axis=0) / np.sum(train))) <= 1e-5\n",
    "pred_probs = predict(X_test, vectorizer, priors, likelihood)\n",
    "proba = pred_probs[:, 1]\n",
    "pred = np.zeros_like(proba)\n",
    "pred[proba>=0.5] = 1\n",
    "metrics = calc_metrics(y_test, pred, proba, labels=[\"ham\", \"spam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Scikit learn NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.965\n",
      "Recall: 0.908\n",
      "Precision: 0.969\n",
      "F1: 0.937\n",
      "accuracy: 0.972\n",
      "      pred_ham  pred_spam\n",
      "ham        895          8\n",
      "spam        25        247\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=2.5, class_prior=[0.5, 0.5])\n",
    "clf.fit(train.toarray(), y_train)\n",
    "pred = clf.predict(test.toarray())\n",
    "proba = clf.predict_proba(test.toarray())[:, 1]\n",
    "metrics = calc_metrics(y_test, pred, proba, labels=[\"ham\", \"spam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['scale_pos_weight'] = sum(y_train==0) / sum(y_train==1)\n",
    "params['learning_rate'] = 0.1\n",
    "params['n_estimators'] = 1000\n",
    "params['max_depth'] = 5\n",
    "params['min_child_weight'] = 100\n",
    "params['gamma'] = 0\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.8\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['seed'] = 27\n",
    "params['n_jobs'] = -1\n",
    "params[\"eval_metric\"] = [\"error\",\"auc\"]\n",
    "params[\"early_stopping_rounds\"] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, y_train)\n",
    "dtest = xgb.DMatrix(test, y_test)\n",
    "eval_set = [(dtrain, \"train\"), (dtest, \"eval\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.168831\ttrain-auc:0.918823\teval-error:0.16766\teval-auc:0.924514\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-error:0.100277\ttrain-auc:0.977128\teval-error:0.108085\teval-auc:0.972736\n",
      "[100]\ttrain-error:0.086864\ttrain-auc:0.980495\teval-error:0.097021\teval-auc:0.973377\n",
      "[150]\ttrain-error:0.08729\ttrain-auc:0.981587\teval-error:0.091915\teval-auc:0.973621\n",
      "[200]\ttrain-error:0.080264\ttrain-auc:0.983037\teval-error:0.08766\teval-auc:0.973951\n",
      "[250]\ttrain-error:0.076858\ttrain-auc:0.984178\teval-error:0.090213\teval-auc:0.974546\n",
      "[300]\ttrain-error:0.076432\ttrain-auc:0.98498\teval-error:0.092766\teval-auc:0.973963\n",
      "Stopping. Best iteration:\n",
      "[257]\ttrain-error:0.076006\ttrain-auc:0.984216\teval-error:0.091064\teval-auc:0.974713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(dtrain=dtrain, num_boost_round=params.get(\"n_estimators\"), \n",
    "                  early_stopping_rounds=params.get(\"early_stopping_rounds\"), \n",
    "                  params=params, evals=eval_set, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.974\n",
      "Recall: 0.926\n",
      "Precision: 0.741\n",
      "F1: 0.824\n",
      "accuracy: 0.908\n",
      "      pred_ham  pred_spam\n",
      "ham        815         88\n",
      "spam        20        252\n"
     ]
    }
   ],
   "source": [
    "pred_proba_xgb = model.predict(dtest)\n",
    "pred_xgb = np.zeros_like(pred_proba_xgb)\n",
    "pred_xgb[pred_proba_xgb>=0.5] = 1\n",
    "xgb_metrics = calc_metrics(y_test, pred_xgb, pred_proba_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
